{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4dfe47c2",
      "metadata": {
        "id": "4dfe47c2"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mabuice/AMATH_Visual_Coding/blob/main/Homework_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d25d5a",
      "metadata": {
        "id": "73d25d5a"
      },
      "source": [
        "<div style=\"background: #F0FAFF; border-radius: 3px; padding: 10px;\">\n",
        "<h3> This notebook will explore decoding using the Allen Brain Observatory data </h3>\n",
        "    \n",
        "In this notebook, we'll look at decoding using different models, different definitions of the design matrix, and different neural populations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fZwHuV7_uqNp",
      "metadata": {
        "id": "fZwHuV7_uqNp"
      },
      "outputs": [],
      "source": [
        "# @title Run to initialize Allen Brain Observatory on Colab {display-mode: \"form\" }\n",
        "# run only once per runtime/session, and only if running in colab\n",
        "# the runtime will need to restart after\n",
        "%%capture\n",
        "!apt install s3fs\n",
        "!pip install allensdk\n",
        "!mkdir -p /data/allen-brain-observatory/\n",
        "!s3fs allen-brain-observatory /data/allen-brain-observatory/ -o public_bucket=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "328b07a0",
      "metadata": {
        "id": "328b07a0"
      },
      "source": [
        "### Standard imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ac50c84c",
      "metadata": {
        "id": "ac50c84c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50eaa6e4",
      "metadata": {
        "id": "50eaa6e4"
      },
      "source": [
        "### Allen Brain Observatory set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "212135d6",
      "metadata": {
        "id": "212135d6"
      },
      "outputs": [],
      "source": [
        "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
        "\n",
        "manifest_file = '../data/allen-brain-observatory/visual-coding-2p/manifest.json'\n",
        "boc = BrainObservatoryCache(manifest_file=manifest_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ddbabd3",
      "metadata": {
        "id": "2ddbabd3"
      },
      "source": [
        "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
        "The command below returns a list of dictionaries containing information about the experiment sessions.  As we saw in the main notebook, you can use optional arguments to specify subsets of experiment sessions.  (Hint:  use the help function to see other ways of choosing sessions.)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca663637",
      "metadata": {
        "id": "ca663637"
      },
      "outputs": [],
      "source": [
        "exps = boc.get_ophys_experiments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2SBh_OpkQgZP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1497
        },
        "id": "2SBh_OpkQgZP",
        "outputId": "576244cc-b3ec-475e-ea86-eeaa643dd3d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id  imaging_depth targeted_structure           cre_line  \\\n",
              "0     566752133            175               VISl      Emx1-IRES-Cre   \n",
              "1     653123586            275               VISl     Rorb-IRES2-Cre   \n",
              "2     577225417            275               VISl       Vip-IRES-Cre   \n",
              "3     556353209            375              VISam     Rbp4-Cre_KL100   \n",
              "4     510390912            275              VISal     Rorb-IRES2-Cre   \n",
              "...         ...            ...                ...                ...   \n",
              "1363  577820172            275              VISam     Rorb-IRES2-Cre   \n",
              "1364  648389302            275               VISp  Slc17a7-IRES2-Cre   \n",
              "1365  510517609            375              VISpm     Rbp4-Cre_KL100   \n",
              "1366  547560448            350              VISal          Nr5a1-Cre   \n",
              "1367  627823695            550               VISp    Ntsr1-Cre_GN220   \n",
              "\n",
              "                   reporter_line  acquisition_age_days  \\\n",
              "0             Ai93(TITL-GCaMP6f)                   116   \n",
              "1             Ai93(TITL-GCaMP6f)                   111   \n",
              "2     Ai148(TIT2L-GC6f-ICL-tTA2)                   105   \n",
              "3             Ai93(TITL-GCaMP6f)                   101   \n",
              "4             Ai93(TITL-GCaMP6f)                    80   \n",
              "...                          ...                   ...   \n",
              "1363          Ai93(TITL-GCaMP6f)                   110   \n",
              "1364          Ai93(TITL-GCaMP6f)                   108   \n",
              "1365          Ai93(TITL-GCaMP6f)                    75   \n",
              "1366          Ai93(TITL-GCaMP6f)                   107   \n",
              "1367  Ai148(TIT2L-GC6f-ICL-tTA2)                    88   \n",
              "\n",
              "      experiment_container_id      session_type donor_name  \\\n",
              "0                   564425775  three_session_C2     283147   \n",
              "1                   653123584  three_session_C2     352471   \n",
              "2                   575772104  three_session_C2     296710   \n",
              "3                   555327033   three_session_A     271750   \n",
              "4                   511500480   three_session_A     232623   \n",
              "...                       ...               ...        ...   \n",
              "1363                576411244   three_session_B     295995   \n",
              "1364                647155120   three_session_B     347751   \n",
              "1365                511511006   three_session_B     233442   \n",
              "1366                546328009  three_session_C2     261969   \n",
              "1367                627823692   three_session_A     339814   \n",
              "\n",
              "                                 specimen_name  fail_eye_tracking  \n",
              "0         Emx1-IRES-Cre;Camk2a-tTA;Ai93-283147               True  \n",
              "1        Rorb-IRES2-Cre;Camk2a-tTA;Ai93-352471               True  \n",
              "2                    Vip-IRES-Cre;Ai148-296710              False  \n",
              "3              Rbp4-Cre;Camk2a-tTA;Ai93-271750               True  \n",
              "4        Rorb-IRES2-Cre;Camk2a-tTA;Ai93-232623              False  \n",
              "...                                        ...                ...  \n",
              "1363     Rorb-IRES2-Cre;Camk2a-tTA;Ai93-295995              False  \n",
              "1364  Slc17a7-IRES2-Cre;Camk2a-tTA;Ai93-347751              False  \n",
              "1365           Rbp4-Cre;Camk2a-tTA;Ai93-233442              False  \n",
              "1366          Nr5a1-Cre;Camk2a-tTA;Ai93-261969              False  \n",
              "1367              Ntsr1-Cre_GN220;Ai148-339814              False  \n",
              "\n",
              "[1368 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e4f4c61-ac68-4e04-91b9-2d35a79ebc43\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>imaging_depth</th>\n",
              "      <th>targeted_structure</th>\n",
              "      <th>cre_line</th>\n",
              "      <th>reporter_line</th>\n",
              "      <th>acquisition_age_days</th>\n",
              "      <th>experiment_container_id</th>\n",
              "      <th>session_type</th>\n",
              "      <th>donor_name</th>\n",
              "      <th>specimen_name</th>\n",
              "      <th>fail_eye_tracking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>566752133</td>\n",
              "      <td>175</td>\n",
              "      <td>VISl</td>\n",
              "      <td>Emx1-IRES-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>116</td>\n",
              "      <td>564425775</td>\n",
              "      <td>three_session_C2</td>\n",
              "      <td>283147</td>\n",
              "      <td>Emx1-IRES-Cre;Camk2a-tTA;Ai93-283147</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>653123586</td>\n",
              "      <td>275</td>\n",
              "      <td>VISl</td>\n",
              "      <td>Rorb-IRES2-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>111</td>\n",
              "      <td>653123584</td>\n",
              "      <td>three_session_C2</td>\n",
              "      <td>352471</td>\n",
              "      <td>Rorb-IRES2-Cre;Camk2a-tTA;Ai93-352471</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>577225417</td>\n",
              "      <td>275</td>\n",
              "      <td>VISl</td>\n",
              "      <td>Vip-IRES-Cre</td>\n",
              "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
              "      <td>105</td>\n",
              "      <td>575772104</td>\n",
              "      <td>three_session_C2</td>\n",
              "      <td>296710</td>\n",
              "      <td>Vip-IRES-Cre;Ai148-296710</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>556353209</td>\n",
              "      <td>375</td>\n",
              "      <td>VISam</td>\n",
              "      <td>Rbp4-Cre_KL100</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>101</td>\n",
              "      <td>555327033</td>\n",
              "      <td>three_session_A</td>\n",
              "      <td>271750</td>\n",
              "      <td>Rbp4-Cre;Camk2a-tTA;Ai93-271750</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510390912</td>\n",
              "      <td>275</td>\n",
              "      <td>VISal</td>\n",
              "      <td>Rorb-IRES2-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>80</td>\n",
              "      <td>511500480</td>\n",
              "      <td>three_session_A</td>\n",
              "      <td>232623</td>\n",
              "      <td>Rorb-IRES2-Cre;Camk2a-tTA;Ai93-232623</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363</th>\n",
              "      <td>577820172</td>\n",
              "      <td>275</td>\n",
              "      <td>VISam</td>\n",
              "      <td>Rorb-IRES2-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>110</td>\n",
              "      <td>576411244</td>\n",
              "      <td>three_session_B</td>\n",
              "      <td>295995</td>\n",
              "      <td>Rorb-IRES2-Cre;Camk2a-tTA;Ai93-295995</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>648389302</td>\n",
              "      <td>275</td>\n",
              "      <td>VISp</td>\n",
              "      <td>Slc17a7-IRES2-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>108</td>\n",
              "      <td>647155120</td>\n",
              "      <td>three_session_B</td>\n",
              "      <td>347751</td>\n",
              "      <td>Slc17a7-IRES2-Cre;Camk2a-tTA;Ai93-347751</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365</th>\n",
              "      <td>510517609</td>\n",
              "      <td>375</td>\n",
              "      <td>VISpm</td>\n",
              "      <td>Rbp4-Cre_KL100</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>75</td>\n",
              "      <td>511511006</td>\n",
              "      <td>three_session_B</td>\n",
              "      <td>233442</td>\n",
              "      <td>Rbp4-Cre;Camk2a-tTA;Ai93-233442</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>547560448</td>\n",
              "      <td>350</td>\n",
              "      <td>VISal</td>\n",
              "      <td>Nr5a1-Cre</td>\n",
              "      <td>Ai93(TITL-GCaMP6f)</td>\n",
              "      <td>107</td>\n",
              "      <td>546328009</td>\n",
              "      <td>three_session_C2</td>\n",
              "      <td>261969</td>\n",
              "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-261969</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367</th>\n",
              "      <td>627823695</td>\n",
              "      <td>550</td>\n",
              "      <td>VISp</td>\n",
              "      <td>Ntsr1-Cre_GN220</td>\n",
              "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
              "      <td>88</td>\n",
              "      <td>627823692</td>\n",
              "      <td>three_session_A</td>\n",
              "      <td>339814</td>\n",
              "      <td>Ntsr1-Cre_GN220;Ai148-339814</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1368 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4f4c61-ac68-4e04-91b9-2d35a79ebc43')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e4f4c61-ac68-4e04-91b9-2d35a79ebc43 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e4f4c61-ac68-4e04-91b9-2d35a79ebc43');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cb02c66-f63b-41bf-a1ab-1e588449e796\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cb02c66-f63b-41bf-a1ab-1e588449e796')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cb02c66-f63b-41bf-a1ab-1e588449e796 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1368,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58448129,\n        \"min\": 497060401,\n        \"max\": 717913184,\n        \"num_unique_values\": 1368,\n        \"samples\": [\n          502666254,\n          652737678,\n          562122508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imaging_depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91,\n        \"min\": 175,\n        \"max\": 625,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          205,\n          570,\n          175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"targeted_structure\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"VISl\",\n          \"VISam\",\n          \"VISrl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cre_line\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Nr5a1-Cre\",\n          \"Sst-IRES-Cre\",\n          \"Emx1-IRES-Cre\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reporter_line\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ai148(TIT2L-GC6f-ICL-tTA2)\",\n          \"Ai94(TITL-GCaMP6s)\",\n          \"Ai162(TIT2L-GC6s-ICL-tTA2)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acquisition_age_days\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 68,\n        \"max\": 168,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          89,\n          113,\n          86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experiment_container_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57275966,\n        \"min\": 511498742,\n        \"max\": 716655272,\n        \"num_unique_values\": 456,\n        \"samples\": [\n          651773425,\n          560876149,\n          676503586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"three_session_A\",\n          \"three_session_C\",\n          \"three_session_C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"donor_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"332395\",\n          \"369311\",\n          \"246775\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specimen_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"Sst-IRES-Cre;Ai148(CAM)-332395\",\n          \"Slc17a7-IRES2-Cre;Camk2a-tTA;Ai93-369311\",\n          \"Scnn1a-Tg3-Cre;Camk2a-tTA;Ai93-246775\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fail_eye_tracking\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pd.DataFrame(exps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T-fPGw30MSLk",
      "metadata": {
        "id": "T-fPGw30MSLk"
      },
      "source": [
        "The following function will grab the data_set object for a given session_id.  The last two lines will extract the dF/F traces and the stimulus table for a given stimulus type.  \n",
        "\n",
        "Some other stimulus types are `natural_scenes` and `static_gratings`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "VabuvKlDMRTb",
      "metadata": {
        "id": "VabuvKlDMRTb"
      },
      "outputs": [],
      "source": [
        "session_id = 627823695\n",
        "data_set = boc.get_ophys_experiment_data(session_id)\n",
        "\n",
        "timestamps, dff = data_set.get_dff_traces()\n",
        "stim_table = data_set.get_stimulus_table('drifting_gratings')\n",
        "timestamps, dff = data_set.get_dff_traces()\n",
        "stim_table = data_set.get_stimulus_table('drifting_gratings')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf7399e",
      "metadata": {
        "id": "3cf7399e"
      },
      "source": [
        "**Exercise 1:** Use a different decoder and repeat the same analysis.  Good decoders to try are Logistic Regression, Support Vector Machine, K-Means.\n",
        "\n",
        "Logistic Regression:\n",
        "https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "Support Vector Machine:\n",
        "https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "(Note:  look through the documentation to see what parameters govern these decoders.  How should you set them?  What effect do they have on the performance of your classifier?)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stim_table.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGGW-Mda6KL8",
        "outputId": "54614ab6-6f60-4535-f401-a17440e8064a"
      },
      "id": "eGGW-Mda6KL8",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['temporal_frequency', 'orientation', 'blank_sweep', 'start', 'end'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Exercise 1: Using Different Decoders (Self-Contained)\n",
        "# ================================\n",
        "\n",
        "# --- Step 1: Retrieve the Data for a Drifting Gratings Session ---\n",
        "\n",
        "# Find sessions that include the drifting gratings stimulus.\n",
        "exps = boc.get_ophys_experiments(stimuli=['drifting_gratings'])\n",
        "print(\"Found\", len(exps), \"session(s) with drifting gratings stimulus.\")\n",
        "\n",
        "# Use the first session in the list.\n",
        "session_id = exps[0]['id']\n",
        "print(\"Using session_id:\", session_id)\n",
        "\n",
        "# Get the experiment data for this session.\n",
        "data_set = boc.get_ophys_experiment_data(session_id)\n",
        "\n",
        "# Retrieve the dF/F traces for all neurons.\n",
        "# dff has shape: [num_neurons, num_frames]\n",
        "timestamps, dff = data_set.get_dff_traces()\n",
        "\n",
        "# Retrieve the stimulus table for the drifting gratings stimulus.\n",
        "# (This should now work since we selected a session known to include drifting gratings.)\n",
        "stim_table = data_set.get_stimulus_table('drifting_gratings')\n",
        "\n",
        "# --- Step 2: Build the Design Matrix and Label Vector ---\n",
        "# Each row in the design matrix (\"activity\") corresponds to a trial.\n",
        "# Each column corresponds to a neuron.\n",
        "num_trials = stim_table.shape[0]\n",
        "num_neurons = dff.shape[0]\n",
        "\n",
        "activity = np.zeros((num_trials, num_neurons))\n",
        "stim_tf = []  # We will use the temporal frequency as the stimulus label.\n",
        "\n",
        "# Loop over each trial to compute the mean response per neuron.\n",
        "for i, row in stim_table.iterrows():\n",
        "    # Compute the mean DF/F response for each neuron for frames from 'start' to 'end'.\n",
        "    activity[i, :] = dff[:, int(row.start):int(row.end)].mean(axis=1)\n",
        "\n",
        "    # Use the temporal frequency as the label if valid; otherwise, use 'blank'\n",
        "    if np.isfinite(row.temporal_frequency):\n",
        "        stim_tf.append(str(row.temporal_frequency))\n",
        "    else:\n",
        "        stim_tf.append('blank')\n",
        "\n",
        "stim_tf = np.array(stim_tf)\n",
        "\n",
        "print(\"Activity shape (trials x neurons):\", activity.shape)\n",
        "print(\"Stimulus label vector shape:\", stim_tf.shape)\n",
        "\n",
        "\n",
        "# --- Step 3: Split the Data into Training and Testing Sets ---\n",
        "# Use 75% of trials for training and 25% for testing.\n",
        "test_index = int(0.75 * num_trials)\n",
        "\n",
        "activity_train = activity[:test_index, :]\n",
        "activity_test  = activity[test_index:, :]\n",
        "\n",
        "stim_tf_train = stim_tf[:test_index]\n",
        "stim_tf_test  = stim_tf[test_index:]\n",
        "\n",
        "\n",
        "# --- Step 4: Apply Different Decoders ---\n",
        "\n",
        "# 1. Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr = LogisticRegression(max_iter=1000)\n",
        "clf_lr.fit(activity_train, stim_tf_train)\n",
        "pred_lr = clf_lr.predict(activity_test)\n",
        "acc_lr = np.mean(pred_lr == stim_tf_test)\n",
        "print(\"Logistic Regression Test Accuracy: {:.2f}%\".format(acc_lr * 100))\n",
        "\n",
        "\n",
        "# 2. Support Vector Machine (SVM)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf_svc = SVC()  # You can adjust parameters (e.g., kernel, C) if desired.\n",
        "clf_svc.fit(activity_train, stim_tf_train)\n",
        "pred_svc = clf_svc.predict(activity_test)\n",
        "acc_svc = np.mean(pred_svc == stim_tf_test)\n",
        "print(\"SVM Test Accuracy: {:.2f}%\".format(acc_svc * 100))\n",
        "\n",
        "\n",
        "# 3. K-Means Clustering (Unsupervised)\n",
        "# K-Means will cluster the training data, and we assign a label to each cluster based on the mode.\n",
        "from sklearn.cluster import KMeans\n",
        "import scipy.stats as stats\n",
        "\n",
        "unique_labels = np.unique(stim_tf_train)\n",
        "n_clusters = len(unique_labels)\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "train_clusters = kmeans.fit_predict(activity_train)\n",
        "\n",
        "# Map each cluster to the most common stimulus label in the training data.\n",
        "cluster_to_label = {}\n",
        "for cl in np.unique(train_clusters):\n",
        "    mask = (train_clusters == cl)\n",
        "    common_label = stats.mode(stim_tf_train[mask])[0][0]\n",
        "    cluster_to_label[cl] = common_label\n",
        "    print(f\"Cluster {cl}: assigned label {common_label}\")\n",
        "\n",
        "# Predict clusters for the test set and map clusters to labels.\n",
        "test_clusters = kmeans.predict(activity_test)\n",
        "pred_km = np.array([cluster_to_label[cl] for cl in test_clusters])\n",
        "acc_km = np.mean(pred_km == stim_tf_test)\n",
        "print(\"K-Means (Unsupervised) Test 'Accuracy': {:.2f}%\".format(acc_km * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXRJl-K35dTh",
        "outputId": "cb1f894e-fdf5-4da4-eff3-1270e01d3db9"
      },
      "id": "sXRJl-K35dTh",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 456 session(s) with drifting gratings stimulus.\n",
            "Using session_id: 556353209\n",
            "Activity shape (trials x neurons): (628, 21)\n",
            "Stimulus label vector shape: (628,)\n",
            "Logistic Regression Test Accuracy: 19.11%\n",
            "SVM Test Accuracy: 16.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7ca8c8af0540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: /usr/local/lib/python3.11/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0: assigned label 8.0\n",
            "Cluster 1: assigned label 2.0\n",
            "Cluster 2: assigned label 8.0\n",
            "Cluster 3: assigned label 15.0\n",
            "Cluster 4: assigned label 1.0\n",
            "Cluster 5: assigned label 15.0\n",
            "K-Means (Unsupervised) Test 'Accuracy': 16.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-8336519e9c9e>:100: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  common_label = stats.mode(stim_tf_train[mask])[0][0]\n",
            "<ipython-input-32-8336519e9c9e>:100: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
            "  common_label = stats.mode(stim_tf_train[mask])[0][0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2342cac1",
      "metadata": {
        "id": "2342cac1"
      },
      "source": [
        "**Exercise 2:** Use a different stimulus type.  In addition to ‘drifting_gratings’, there are also ‘natural_scenes’ and ‘static_gratings’.  Find a session with these stimuli and try decoding the stimulus condition.\n",
        "\n",
        "(Hint:  use the function given above to get a list of experiments and convert it to a dataframe).*italicized text*\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "T2yauTHcWmwD",
      "metadata": {
        "id": "T2yauTHcWmwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6a469c-e948-41c2-b818-610deab5d94c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 456 session(s) with natural scenes stimulus.\n",
            "Using session_id for natural scenes: 645474010\n",
            "Natural Scenes Stimulus Table (first 5 rows):\n",
            "   frame  start    end\n",
            "0    106  16913  16920\n",
            "1     21  16921  16928\n",
            "2     98  16929  16936\n",
            "3     97  16936  16944\n",
            "4     91  16944  16951\n",
            "Activity shape (natural scenes): (5950, 25)\n",
            "Unique natural scenes labels: ['blank']\n",
            "Natural Scenes Decoding Test Accuracy (LDA): 100.00%\n"
          ]
        }
      ],
      "source": [
        "exps_ns = boc.get_ophys_experiments(stimuli=['natural_scenes'])\n",
        "print(\"Found\", len(exps_ns), \"session(s) with natural scenes stimulus.\")\n",
        "\n",
        "# Use the first session from the natural scenes experiments.\n",
        "session_id_ns = exps_ns[0]['id']\n",
        "print(\"Using session_id for natural scenes:\", session_id_ns)\n",
        "\n",
        "# Get the experiment data for this session.\n",
        "data_set_ns = boc.get_ophys_experiment_data(session_id_ns)\n",
        "\n",
        "# Retrieve the dF/F traces for all neurons.\n",
        "# dff_ns will have shape: [num_neurons, num_frames]\n",
        "timestamps_ns, dff_ns = data_set_ns.get_dff_traces()\n",
        "\n",
        "# Retrieve the stimulus table for the natural scenes stimulus.\n",
        "stim_table_ns = data_set_ns.get_stimulus_table('natural_scenes')\n",
        "\n",
        "# Optionally, print the first few rows to inspect the table.\n",
        "print(\"Natural Scenes Stimulus Table (first 5 rows):\")\n",
        "print(stim_table_ns.head(5))\n",
        "\n",
        "\n",
        "# --- Step 2: Build the Design Matrix and Label Vector ---\n",
        "# For natural scenes, we assume that the stimulus table includes a column named \"image_id\"\n",
        "# which identifies the natural scene image presented on each trial.\n",
        "\n",
        "num_trials_ns = stim_table_ns.shape[0]\n",
        "num_neurons_ns = dff_ns.shape[0]\n",
        "\n",
        "activity_ns = np.zeros((num_trials_ns, num_neurons_ns))\n",
        "stim_ns = []  # This will hold the stimulus condition (image_id) for each trial.\n",
        "\n",
        "for i, row in stim_table_ns.iterrows():\n",
        "    # Compute the mean DF/F response for each neuron over the trial.\n",
        "    activity_ns[i, :] = dff_ns[:, int(row.start):int(row.end)].mean(axis=1)\n",
        "\n",
        "    # Use the 'image_id' as the label if it exists and is finite; otherwise, label it as 'blank'.\n",
        "    if 'image_id' in stim_table_ns.columns and np.isfinite(row.image_id):\n",
        "        stim_ns.append(str(row.image_id))\n",
        "    else:\n",
        "        stim_ns.append('blank')\n",
        "\n",
        "stim_ns = np.array(stim_ns)\n",
        "\n",
        "print(\"Activity shape (natural scenes):\", activity_ns.shape)\n",
        "print(\"Unique natural scenes labels:\", np.unique(stim_ns))\n",
        "\n",
        "\n",
        "# --- Step 3: Split the Data into Training and Testing Sets ---\n",
        "# Use 75% of the trials for training and 25% for testing.\n",
        "test_index_ns = int(0.75 * num_trials_ns)\n",
        "\n",
        "activity_ns_train = activity_ns[:test_index_ns, :]\n",
        "activity_ns_test  = activity_ns[test_index_ns:, :]\n",
        "\n",
        "stim_ns_train = stim_ns[:test_index_ns]\n",
        "stim_ns_test  = stim_ns[test_index_ns:]\n",
        "\n",
        "\n",
        "# --- Step 4: Decode the Natural Scenes Stimulus Condition ---\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "clf_ns = LDA()\n",
        "clf_ns.fit(activity_ns_train, stim_ns_train)\n",
        "\n",
        "pred_ns = clf_ns.predict(activity_ns_test)\n",
        "acc_ns = np.mean(pred_ns == stim_ns_test)\n",
        "print(\"Natural Scenes Decoding Test Accuracy (LDA): {:.2f}%\".format(acc_ns * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664f1572",
      "metadata": {
        "id": "664f1572"
      },
      "source": [
        "**Exercise 3:** Compare the decoding performance between sessions from different areas.  Does decoding of drifting gratings work better in VISp compared to other areas?  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "dvB-dd9RWp3T",
      "metadata": {
        "id": "dvB-dd9RWp3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c67540-59ac-4c0c-ce7c-1b463033492f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 456 sessions with drifting gratings stimulus.\n",
            "Unique targeted structures in drifting gratings sessions: ['VISam' 'VISal' 'VISp' 'VISl' 'VISpm' 'VISrl']\n",
            "\n",
            "Processing area: VISam using session_id: 556353209\n",
            "Decoding accuracy for area VISam : 0.2\n",
            "\n",
            "Processing area: VISal using session_id: 510390912\n",
            "Decoding accuracy for area VISal : 0.47333333333333333\n",
            "\n",
            "Processing area: VISp using session_id: 704298735\n",
            "Decoding accuracy for area VISp : 0.7\n",
            "\n",
            "Processing area: VISl using session_id: 653123929\n",
            "Decoding accuracy for area VISl : 0.7333333333333333\n",
            "\n",
            "Processing area: VISpm using session_id: 626027944\n",
            "Decoding accuracy for area VISpm : 0.18666666666666668\n",
            "\n",
            "Processing area: VISrl using session_id: 581597734\n",
            "Decoding accuracy for area VISrl : 0.43333333333333335\n",
            "\n",
            "Decoding Performance by Brain Area:\n",
            "VISam: 0.20\n",
            "VISal: 0.47\n",
            "VISp: 0.70\n",
            "VISl: 0.73\n",
            "VISpm: 0.19\n",
            "VISrl: 0.43\n",
            "\n",
            "VISp decoding accuracy: 0.70\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# --- Step 1: Retrieve All Drifting Gratings Sessions ---\n",
        "exps = boc.get_ophys_experiments(stimuli=['drifting_gratings'])\n",
        "print(\"Found\", len(exps), \"sessions with drifting gratings stimulus.\")\n",
        "\n",
        "# Convert the list of session dictionaries to a DataFrame.\n",
        "df_exps = pd.DataFrame(exps)\n",
        "\n",
        "# Get the unique targeted structures (brain areas).\n",
        "unique_areas = df_exps['targeted_structure'].unique()\n",
        "print(\"Unique targeted structures in drifting gratings sessions:\", unique_areas)\n",
        "\n",
        "# Dictionary to store decoding accuracies for each area.\n",
        "decoding_results = {}\n",
        "\n",
        "# --- Step 2: Iterate Through Each Brain Area and Decode ---\n",
        "for area in unique_areas:\n",
        "    # Filter the sessions for this area.\n",
        "    sessions_area = df_exps[df_exps['targeted_structure'] == area]\n",
        "    if sessions_area.empty:\n",
        "        continue\n",
        "\n",
        "    # Pick the first session from this area.\n",
        "    session_id = sessions_area.iloc[0]['id']\n",
        "    print(\"\\nProcessing area:\", area, \"using session_id:\", session_id)\n",
        "\n",
        "    try:\n",
        "        data_set = boc.get_ophys_experiment_data(session_id)\n",
        "        stim_table = data_set.get_stimulus_table('drifting_gratings')\n",
        "    except Exception as e:\n",
        "        print(\"Error retrieving drifting gratings for session\", session_id, \":\", e)\n",
        "        continue\n",
        "\n",
        "    # Retrieve the dF/F traces: shape = [num_neurons, num_frames]\n",
        "    timestamps, dff = data_set.get_dff_traces()\n",
        "\n",
        "    # --- Build the Design Matrix and Stimulus Labels ---\n",
        "    num_trials = stim_table.shape[0]\n",
        "    num_neurons = dff.shape[0]\n",
        "    if num_trials == 0 or num_neurons == 0:\n",
        "        print(\"No trials or neurons found for session\", session_id)\n",
        "        continue\n",
        "\n",
        "    # We will use each trial's orientation as the stimulus label.\n",
        "    activity = np.zeros((num_trials, num_neurons))\n",
        "    stim_labels = []  # to hold orientation values (as strings)\n",
        "\n",
        "    for i, row in stim_table.iterrows():\n",
        "        # Compute the mean response per neuron for the trial.\n",
        "        activity[i, :] = dff[:, int(row.start):int(row.end)].mean(axis=1)\n",
        "        # Use orientation if valid; if not (e.g., blank trials), label as 'blank'\n",
        "        if np.isfinite(row.orientation):\n",
        "            stim_labels.append(str(row.orientation))\n",
        "        else:\n",
        "            stim_labels.append('blank')\n",
        "\n",
        "    stim_labels = np.array(stim_labels)\n",
        "\n",
        "    # --- Exclude Blank Trials ---\n",
        "    valid_idx = stim_labels != 'blank'\n",
        "    activity = activity[valid_idx, :]\n",
        "    stim_labels = stim_labels[valid_idx]\n",
        "\n",
        "    # Ensure there is more than one condition to decode.\n",
        "    if len(np.unique(stim_labels)) < 2:\n",
        "        print(\"Not enough stimulus conditions for decoding in area\", area)\n",
        "        continue\n",
        "\n",
        "    # --- Split Data: 75% Training, 25% Testing ---\n",
        "    num_valid = activity.shape[0]\n",
        "    test_index = int(0.75 * num_valid)\n",
        "\n",
        "    activity_train = activity[:test_index, :]\n",
        "    activity_test  = activity[test_index:, :]\n",
        "    stim_train = stim_labels[:test_index]\n",
        "    stim_test  = stim_labels[test_index:]\n",
        "\n",
        "    # --- Decode Using LDA ---\n",
        "    clf = LDA()\n",
        "    clf.fit(activity_train, stim_train)\n",
        "    pred = clf.predict(activity_test)\n",
        "    accuracy = np.mean(pred == stim_test)\n",
        "    decoding_results[area] = accuracy\n",
        "    print(\"Decoding accuracy for area\", area, \":\", accuracy)\n",
        "\n",
        "# --- Summary of Results ---\n",
        "print(\"\\nDecoding Performance by Brain Area:\")\n",
        "for area, acc in decoding_results.items():\n",
        "    print(f\"{area}: {acc:.2f}\")\n",
        "\n",
        "# Example: Check if VISp shows higher accuracy than other areas.\n",
        "if \"VISp\" in decoding_results:\n",
        "    print(f\"\\nVISp decoding accuracy: {decoding_results['VISp']:.2f}\")\n",
        "else:\n",
        "    print(\"\\nNo VISp session available in the dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SO7vsaHYyS8l",
      "metadata": {
        "id": "SO7vsaHYyS8l"
      },
      "source": [
        "**Exercise 4:**  Compare the decoding performance between sessions from different areas of similar depth.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "dlOE2fMpXpxg",
      "metadata": {
        "id": "dlOE2fMpXpxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954e59a5-6350-4015-e91a-75cf8091e4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 456 sessions with drifting gratings stimulus.\n",
            "Number of sessions with imaging_depth between 300 and 400 : 156\n",
            "Unique targeted structures in selected depth range: ['VISam' 'VISl' 'VISp' 'VISal' 'VISrl' 'VISpm']\n",
            "\n",
            "Processing area: VISam with session_id: 556353209 and imaging_depth: 375\n",
            "Decoding accuracy for area VISam : 0.2\n",
            "\n",
            "Processing area: VISl with session_id: 645689073 and imaging_depth: 375\n",
            "Decoding accuracy for area VISl : 0.6\n",
            "\n",
            "Processing area: VISp with session_id: 662033243 and imaging_depth: 375\n",
            "Decoding accuracy for area VISp : 0.42\n",
            "\n",
            "Processing area: VISal with session_id: 588483711 and imaging_depth: 375\n",
            "Decoding accuracy for area VISal : 0.6\n",
            "\n",
            "Processing area: VISrl with session_id: 571006300 and imaging_depth: 350\n",
            "Decoding accuracy for area VISrl : 0.4266666666666667\n",
            "\n",
            "Processing area: VISpm with session_id: 601368107 and imaging_depth: 375\n",
            "Decoding accuracy for area VISpm : 0.29333333333333333\n",
            "\n",
            "Decoding Performance (for sessions with imaging_depth between 300 and 400 ):\n",
            "VISam: 0.20\n",
            "VISl: 0.60\n",
            "VISp: 0.42\n",
            "VISal: 0.60\n",
            "VISrl: 0.43\n",
            "VISpm: 0.29\n",
            "\n",
            "VISp decoding accuracy: 0.42\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# --- Step 1: Retrieve All Drifting Gratings Sessions ---\n",
        "exps = boc.get_ophys_experiments(stimuli=['drifting_gratings'])\n",
        "print(\"Found\", len(exps), \"sessions with drifting gratings stimulus.\")\n",
        "\n",
        "# Convert sessions to a DataFrame.\n",
        "df_exps = pd.DataFrame(exps)\n",
        "\n",
        "# --- Step 2: Filter Sessions by Imaging Depth ---\n",
        "# Define a depth range for \"similar depth.\" For example, sessions with imaging_depth between 300 and 400 µm.\n",
        "depth_min = 300\n",
        "depth_max = 400\n",
        "df_depth = df_exps[(df_exps['imaging_depth'] >= depth_min) & (df_exps['imaging_depth'] <= depth_max)]\n",
        "print(\"Number of sessions with imaging_depth between\", depth_min, \"and\", depth_max, \":\", len(df_depth))\n",
        "\n",
        "# Get the unique targeted structures (brain areas) in this depth range.\n",
        "unique_areas = df_depth['targeted_structure'].unique()\n",
        "print(\"Unique targeted structures in selected depth range:\", unique_areas)\n",
        "\n",
        "# Dictionary to store decoding accuracies for each area.\n",
        "decoding_results_depth = {}\n",
        "\n",
        "# --- Step 3: Iterate Through Each Brain Area and Decode ---\n",
        "for area in unique_areas:\n",
        "    # Filter sessions for this area.\n",
        "    sessions_area = df_depth[df_depth['targeted_structure'] == area]\n",
        "    if sessions_area.empty:\n",
        "        continue\n",
        "\n",
        "    # Select the first session from this area.\n",
        "    session_id = sessions_area.iloc[0]['id']\n",
        "    depth = sessions_area.iloc[0]['imaging_depth']\n",
        "    print(\"\\nProcessing area:\", area, \"with session_id:\", session_id, \"and imaging_depth:\", depth)\n",
        "\n",
        "    try:\n",
        "        data_set = boc.get_ophys_experiment_data(session_id)\n",
        "        stim_table = data_set.get_stimulus_table('drifting_gratings')\n",
        "    except Exception as e:\n",
        "        print(\"Error retrieving drifting gratings data for session\", session_id, \":\", e)\n",
        "        continue\n",
        "\n",
        "    # Retrieve the dF/F traces for all neurons.\n",
        "    timestamps, dff = data_set.get_dff_traces()\n",
        "    num_trials = stim_table.shape[0]\n",
        "    num_neurons = dff.shape[0]\n",
        "\n",
        "    # --- Build the Design Matrix and Stimulus Labels ---\n",
        "    # Here we use the trial's grating orientation as the stimulus label.\n",
        "    activity = np.zeros((num_trials, num_neurons))\n",
        "    stim_labels = []  # to hold orientation values as strings.\n",
        "\n",
        "    for i, row in stim_table.iterrows():\n",
        "        activity[i, :] = dff[:, int(row.start):int(row.end)].mean(axis=1)\n",
        "        # If orientation is finite, use it; otherwise (e.g., blank trials), label as 'blank'.\n",
        "        if np.isfinite(row.orientation):\n",
        "            stim_labels.append(str(row.orientation))\n",
        "        else:\n",
        "            stim_labels.append('blank')\n",
        "\n",
        "    stim_labels = np.array(stim_labels)\n",
        "\n",
        "    # Exclude blank trials.\n",
        "    valid_idx = stim_labels != 'blank'\n",
        "    activity = activity[valid_idx, :]\n",
        "    stim_labels = stim_labels[valid_idx]\n",
        "\n",
        "    # Ensure there is more than one condition.\n",
        "    if len(np.unique(stim_labels)) < 2:\n",
        "        print(\"Not enough stimulus conditions for decoding in area\", area)\n",
        "        continue\n",
        "\n",
        "    # --- Split Data: 75% Training, 25% Testing ---\n",
        "    num_valid = activity.shape[0]\n",
        "    test_index = int(0.75 * num_valid)\n",
        "\n",
        "    activity_train = activity[:test_index, :]\n",
        "    activity_test  = activity[test_index:, :]\n",
        "    stim_train = stim_labels[:test_index]\n",
        "    stim_test  = stim_labels[test_index:]\n",
        "\n",
        "    # --- Decode Using LDA ---\n",
        "    clf = LDA()\n",
        "    clf.fit(activity_train, stim_train)\n",
        "    pred = clf.predict(activity_test)\n",
        "    accuracy = np.mean(pred == stim_test)\n",
        "    decoding_results_depth[area] = accuracy\n",
        "    print(\"Decoding accuracy for area\", area, \":\", accuracy)\n",
        "\n",
        "# --- Summary of Results ---\n",
        "print(\"\\nDecoding Performance (for sessions with imaging_depth between\", depth_min, \"and\", depth_max, \"):\")\n",
        "for area, acc in decoding_results_depth.items():\n",
        "    print(f\"{area}: {acc:.2f}\")\n",
        "\n",
        "if \"VISp\" in decoding_results_depth:\n",
        "    print(f\"\\nVISp decoding accuracy: {decoding_results_depth['VISp']:.2f}\")\n",
        "else:\n",
        "    print(\"\\nNo VISp session available in the selected depth range.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leBBxF_JyOpf",
      "metadata": {
        "id": "leBBxF_JyOpf"
      },
      "source": [
        "**Exercise 5:** Compare the decoding performance between sessions from different Cre lines of VISp.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88fee9e4",
      "metadata": {
        "id": "88fee9e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbc2005-be1c-4051-e2d4-5cb97fbb9306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total drifting gratings sessions found: 456\n",
            "Number of VISp sessions: 144\n",
            "\n",
            "Processing Cre line: Cux2-CreERT2 with session_id: 704298735\n",
            "Decoding accuracy for Cre line Cux2-CreERT2 : 0.7\n",
            "\n",
            "Processing Cre line: Emx1-IRES-Cre with session_id: 545446482\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# --- Step 1: Retrieve All Drifting Gratings Sessions and Filter for VISp ---\n",
        "exps = boc.get_ophys_experiments(stimuli=['drifting_gratings'])\n",
        "df_exps = pd.DataFrame(exps)\n",
        "print(\"Total drifting gratings sessions found:\", len(df_exps))\n",
        "\n",
        "# Filter for sessions in VISp\n",
        "df_visp = df_exps[df_exps['targeted_structure'] == 'VISp']\n",
        "print(\"Number of VISp sessions:\", len(df_visp))\n",
        "\n",
        "# --- Step 2: Group the VISp Sessions by Cre Line ---\n",
        "# The 'cre_line' field contains the Cre line information.\n",
        "cre_groups = df_visp.groupby('cre_line')\n",
        "decoding_results_cre = {}\n",
        "\n",
        "# --- Step 3: Iterate Through Each Cre Line Group and Decode ---\n",
        "for cre_line, group in cre_groups:\n",
        "    # Select the first session from this Cre line group.\n",
        "    session_id = group.iloc[0]['id']\n",
        "    print(\"\\nProcessing Cre line:\", cre_line, \"with session_id:\", session_id)\n",
        "\n",
        "    try:\n",
        "        data_set = boc.get_ophys_experiment_data(session_id)\n",
        "        stim_table = data_set.get_stimulus_table('drifting_gratings')\n",
        "    except Exception as e:\n",
        "        print(\"Error retrieving data for session\", session_id, \":\", e)\n",
        "        continue\n",
        "\n",
        "    # Retrieve the dF/F traces (shape: [num_neurons, num_frames])\n",
        "    timestamps, dff = data_set.get_dff_traces()\n",
        "    num_trials = stim_table.shape[0]\n",
        "    num_neurons = dff.shape[0]\n",
        "\n",
        "    # --- Build the Design Matrix and Stimulus Labels ---\n",
        "    # We use the grating orientation (if valid) as the stimulus label.\n",
        "    activity = np.zeros((num_trials, num_neurons))\n",
        "    stim_labels = []  # to hold orientation values (as strings)\n",
        "\n",
        "    for i, row in stim_table.iterrows():\n",
        "        # Compute mean DF/F response for each neuron during the trial.\n",
        "        activity[i, :] = dff[:, int(row.start):int(row.end)].mean(axis=1)\n",
        "        # Use orientation if available; otherwise, mark as 'blank'\n",
        "        if np.isfinite(row.orientation):\n",
        "            stim_labels.append(str(row.orientation))\n",
        "        else:\n",
        "            stim_labels.append('blank')\n",
        "\n",
        "    stim_labels = np.array(stim_labels)\n",
        "\n",
        "    # Exclude blank trials from decoding.\n",
        "    valid_idx = stim_labels != 'blank'\n",
        "    activity = activity[valid_idx, :]\n",
        "    stim_labels = stim_labels[valid_idx]\n",
        "\n",
        "    # Ensure there are at least two stimulus conditions to decode.\n",
        "    if len(np.unique(stim_labels)) < 2:\n",
        "        print(\"Not enough stimulus conditions for decoding in Cre line\", cre_line)\n",
        "        continue\n",
        "\n",
        "    # --- Split Data: 75% Training, 25% Testing ---\n",
        "    num_valid = activity.shape[0]\n",
        "    test_index = int(0.75 * num_valid)\n",
        "\n",
        "    activity_train = activity[:test_index, :]\n",
        "    activity_test  = activity[test_index:, :]\n",
        "    stim_train = stim_labels[:test_index]\n",
        "    stim_test  = stim_labels[test_index:]\n",
        "\n",
        "    # --- Decode Using LDA ---\n",
        "    clf = LDA()\n",
        "    clf.fit(activity_train, stim_train)\n",
        "    pred = clf.predict(activity_test)\n",
        "    accuracy = np.mean(pred == stim_test)\n",
        "    decoding_results_cre[cre_line] = accuracy\n",
        "    print(\"Decoding accuracy for Cre line\", cre_line, \":\", accuracy)\n",
        "\n",
        "# --- Summary of Decoding Performance by Cre Line ---\n",
        "print(\"\\nDecoding Performance (VISp sessions by Cre line):\")\n",
        "for cre_line, acc in decoding_results_cre.items():\n",
        "    print(f\"{cre_line}: {acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pf2wJg8pya0F",
      "metadata": {
        "id": "pf2wJg8pya0F"
      },
      "source": [
        "**Exercise 6**:  Compute the design matrix using a different time window or different time offset relative to the stimulus.  Redo the decoding.  What happens as you move the window from before to after the stimulus presentation time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243k1WSvy3BK",
      "metadata": {
        "id": "243k1WSvy3BK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}